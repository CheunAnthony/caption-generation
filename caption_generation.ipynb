{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1cqLmk4feht"
      },
      "source": [
        "# Image Caption Generator\n",
        "\n",
        "In this project, we built an image caption generator. The generator is capable of generating a caption based on the image supplied to it. This project combines computer vision and natural language processing using a combined architecture of a CNN and an LSTM. The dataset chosen to train our model can be downloaded from this github https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip and https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip. The Flickr_8k_text folder contains the Flickr8k.token file, which is the main file in our dataset and contains the names of the images and their respective captions separated by a new line.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hBHthLX6EVB"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from pickle import dump, load\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer # Changed import location\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import add # Changed import location\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.utils import custom_object_scope\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_DYnB3p-GRi"
      },
      "outputs": [],
      "source": [
        "zip_file_path = '/content/Flickr8k_Dataset.zip'\n",
        "extract_path = '/content/images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtrbF_c_-wzw"
      },
      "outputs": [],
      "source": [
        "# This will uncompress our file ans store it to our extract_path\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2acjI3n5APy0"
      },
      "outputs": [],
      "source": [
        "# Load our data contains in a folder\n",
        "def load_data(filename):\n",
        "  file = open(filename,'r')\n",
        "  text = file.read()\n",
        "  file.close()\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGcvVmnOAvxy"
      },
      "outputs": [],
      "source": [
        "# Load our images, each image will associated with five captions\n",
        "def get_images_with_captions(filename):\n",
        "  file = load_data(filename)\n",
        "  captions = file.split('\\n')\n",
        "  descriptions = {}\n",
        "  for caption in captions[:-1]:\n",
        "    img,caption = caption.split('\\t')\n",
        "    if img[:-2] not in descriptions:\n",
        "      descriptions[img[:-2]] = [caption]\n",
        "    else:\n",
        "      descriptions[img[:-2]].append(caption)\n",
        "  return descriptions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc3P5bH4CLGi"
      },
      "outputs": [],
      "source": [
        "# This method cleans up our text by removing punctuation and words containing numbers, and lowering words.\n",
        "def cleaning_text(captions):\n",
        "  table = str.maketrans('','',string.punctuation)\n",
        "  for img,caps in captions.items():\n",
        "    for i,img_caption in enumerate(caps):\n",
        "            img_caption.replace(\"-\",\" \")\n",
        "            desc = img_caption.split()\n",
        "            desc = [word.lower() for word in desc]\n",
        "            desc = [word.translate(table) for word in desc]\n",
        "            desc = [word for word in desc if(len(word)>1)]\n",
        "            desc = [word for word in desc if(word.isalpha())]\n",
        "            img_caption = ' '.join(desc)\n",
        "            captions[img][i]= img_caption\n",
        "    return captions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdN1JGJPDnhN"
      },
      "outputs": [],
      "source": [
        "# We create with this function our vocabulary\n",
        "def build_text_vocabulary(descriptions):\n",
        "  vocab = set()\n",
        "  for key in descriptions.keys():\n",
        "    [vocab.update(d.split()) for d in descriptions[key]]\n",
        "  return vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3wi7IELEr-s"
      },
      "outputs": [],
      "source": [
        "# saving the description in a file\n",
        "def save_descriptions(descriptions,filename):\n",
        "  lines = list()\n",
        "  for key, desc_list in descriptions.items():\n",
        "    for desc in desc_list:\n",
        "      lines.append(key + '\\t' + desc )\n",
        "    data = \"\\n\".join(lines)\n",
        "  file = open(filename,\"w\")\n",
        "  file.write(data)\n",
        "  file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFHPoMK2NL45"
      },
      "outputs": [],
      "source": [
        "# Extract features from our images by passing them to our pre-built model.\n",
        "def extract_features_from_images(directory):\n",
        "  model = Xception(include_top=False,pooling='avg')\n",
        "  features = {}\n",
        "  for img in tqdm(os.listdir(directory)):\n",
        "    filename = directory + \"/\" + img\n",
        "    image = Image.open(filename)\n",
        "    image = image.resize((299,299))\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = image/127.5\n",
        "    image = image - 1.0\n",
        "    feature = model.predict(image)\n",
        "    features[img] = feature\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_hwLQ1gE-ZG"
      },
      "outputs": [],
      "source": [
        "# Here are the path from our dataser, the token file and the folder containing the images\n",
        "dataset_text = \"/content/text/Flickr8k.token.txt\"\n",
        "dataset_images = \"/content/images/Flicker8k_Dataset\"\n",
        "#filename = dataset_text + \"/\" + \"Flickr8k.token.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eft9p7z8J1DP",
        "outputId": "dae3d35b-2e7d-4b15-a2f0-82809abd1ed0"
      },
      "outputs": [],
      "source": [
        "descriptions = get_images_with_captions(dataset_text)\n",
        "print(\"Length of descriptions =\" ,len(descriptions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTksJVp0R5Hq",
        "outputId": "63e54d88-b0a5-461d-c1f0-13be6f7866d2"
      },
      "outputs": [],
      "source": [
        "#for each image it will find find five captions that describe the image\n",
        "descriptions['2094543127_46d2f1fedf.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cLQU1D_LAlX"
      },
      "outputs": [],
      "source": [
        "#cleaning the datas by removing from lower casing,punctuations and word containing numbers\n",
        "clean_descriptions = cleaning_text(descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwNNh2pcTBfM",
        "outputId": "2432f9e4-b310-4859-ef92-ff0e6da466e0"
      },
      "outputs": [],
      "source": [
        "clean_descriptions['2094543127_46d2f1fedf.jpg']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPyPkGavLtTf"
      },
      "outputs": [],
      "source": [
        "#building our vocabulary using our clean text description\n",
        "vocabulary = build_text_vocabulary(clean_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGvNLWcDTot3",
        "outputId": "0d646b61-4b59-4922-b45d-3e8201673f18"
      },
      "outputs": [],
      "source": [
        "vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2XmTQpjMNuE"
      },
      "outputs": [],
      "source": [
        "#saving our descriptions after the preprocessing this will avoid us to repeat the process\n",
        "save_descriptions(clean_descriptions, \"descriptions.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtJ102osMh7i"
      },
      "outputs": [],
      "source": [
        "features = extract_features_from_images(dataset_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qL9lOfbYUaEg"
      },
      "outputs": [],
      "source": [
        "dump(features, open(\"features.p\",\"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lTBexOwYd-b"
      },
      "outputs": [],
      "source": [
        "features = load(open(\"/content/features.p\",\"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfTe31pqu2bT"
      },
      "outputs": [],
      "source": [
        "def load_photos(filename):\n",
        "    file = load_data(filename)\n",
        "    photos = file.split(\"\\n\")[:-1]\n",
        "    return photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHz58hiOvXRO"
      },
      "outputs": [],
      "source": [
        "def load_clean_descriptions(filename, photos):\n",
        "\n",
        "  file = load_data(filename)\n",
        "  descriptions = {}\n",
        "  for line in file.split(\"\\n\"):\n",
        "    words = line.split()\n",
        "    if len(words)<1 :\n",
        "      continue\n",
        "    image, image_caption = words[0], words[1:]\n",
        "    if image in photos:\n",
        "      if image not in descriptions:\n",
        "        descriptions[image] = []\n",
        "        desc = '<start> ' + \" \".join(image_caption) + ' <end>'\n",
        "        descriptions[image].append(desc)\n",
        "  return descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tqAemhIvlCL"
      },
      "outputs": [],
      "source": [
        "def load_features(photos):\n",
        "    all_features = load(open(\"features.p\",\"rb\"))\n",
        "    features = {k:all_features[k] for k in photos}\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fH1IZlqwoGt"
      },
      "outputs": [],
      "source": [
        "train_imgs = load_photos(\"/content/text/Flickr_8k.trainImages.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IGc-z5xxBXi"
      },
      "outputs": [],
      "source": [
        "train_descriptions = load_clean_descriptions(\"/content/descriptions.txt\", train_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONwTFX_47NFi"
      },
      "outputs": [],
      "source": [
        "train_features = load_features(train_imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_9drcbAxSfC"
      },
      "outputs": [],
      "source": [
        "def dict_to_list(descriptions):\n",
        "  all_desc = []\n",
        "  for key in descriptions.keys():\n",
        "    [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCEsxQ5nxmrf"
      },
      "outputs": [],
      "source": [
        "def create_tokenizer(descriptions):\n",
        "  desc_list = dict_to_list(descriptions)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(desc_list)\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgR96626yijb"
      },
      "outputs": [],
      "source": [
        "def max_length(descriptions):\n",
        "  desc_list = dict_to_list(descriptions)\n",
        "  return max(len(d.split()) for d in desc_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdZsuQn9x1A_"
      },
      "outputs": [],
      "source": [
        "tokenizer = create_tokenizer(train_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyXuL3ckx3uW"
      },
      "outputs": [],
      "source": [
        "dump(tokenizer, open('tokenizer.p', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vizurc2yyWuB",
        "outputId": "3296e99a-e985-4dd2-eaf2-4af0e25426e5"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpIxiLh4ydQ3",
        "outputId": "fdd33210-a385-49ca-c931-ec4984e4c675"
      },
      "outputs": [],
      "source": [
        "max_length = max_length(descriptions)\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAV-HSc1z274"
      },
      "outputs": [],
      "source": [
        "def create_sequences(tokenizer, max_length, desc_list, feature):\n",
        "  X1, X2, y = list(), list(), list()\n",
        "  for desc in desc_list:\n",
        "    # encode the sequence\n",
        "    seq = tokenizer.texts_to_sequences([desc])[0]\n",
        "    # split one sequence into multiple X,y pairs\n",
        "    for i in range(1, len(seq)):\n",
        "      # split into input and output pair\n",
        "      in_seq, out_seq = seq[:i], seq[i]\n",
        "      # pad input sequence\n",
        "      in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "      # encode output sequence\n",
        "      out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "      # store\n",
        "      X1.append(feature)\n",
        "      X2.append(in_seq)\n",
        "      y.append(out_seq)\n",
        "  return np.array(X1), np.array(X2), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTK3C3Zpyqd3"
      },
      "outputs": [],
      "source": [
        "def data_generator(descriptions, features, tokenizer, max_length):\n",
        "  while 1:\n",
        "    for key, description_list in descriptions.items():\n",
        "      feature = features[key][0]\n",
        "      input_image, input_sequence, output_word = create_sequences(tokenizer, max_length, description_list, feature)\n",
        "      #yield [[input_image, input_sequence], output_word]\n",
        "      #yield ([input_image,input_sequence],output_word)\n",
        "      yield ((input_image,input_sequence),output_word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT8lPRKZ1EKn"
      },
      "outputs": [],
      "source": [
        "[a,b],c = next(data_generator(train_descriptions, features, tokenizer, max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVAjYLicAUaP",
        "outputId": "e3656f08-5f9e-4329-c38c-796dc8610213"
      },
      "outputs": [],
      "source": [
        "a.shape, b.shape, c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIqpuOmt3a86"
      },
      "outputs": [],
      "source": [
        "# it is the numbers of features that we have\n",
        "input_shape = 2048\n",
        "epochs = 10\n",
        "steps = len(train_descriptions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkXDxcgR1RxW"
      },
      "outputs": [],
      "source": [
        "def custom_model(vocab_size, max_length,input_shape):\n",
        "  input = Input(shape=(input_shape,))\n",
        "  x = Dropout(0.1)(input)\n",
        "  x = Dense(256, activation='relu')(x)\n",
        "\n",
        "  lstminput = Input(shape=(max_length,))\n",
        "  x2 = Embedding(vocab_size,256,mask_zero=True)(lstminput)\n",
        "  x2 = Dropout(0.5)(x2)\n",
        "  x2 = LSTM(256)(x2)\n",
        "\n",
        "  decoder = add([x,x2])\n",
        "  decoder = Dense(256,activation='relu')(decoder)\n",
        "  output = Dense(vocab_size,activation='softmax')(decoder)\n",
        "\n",
        "  model = Model(inputs=[input,lstminput],outputs=output)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94zoAWC67XL9"
      },
      "outputs": [],
      "source": [
        "simple_model = custom_model(vocab_size, max_length,input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "BgpmavXa7bRE",
        "outputId": "05926c5a-08e6-483f-88a9-dbd5aafd720a"
      },
      "outputs": [],
      "source": [
        "simple_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iOVqfmB7r4i",
        "outputId": "f5d22843-04e0-44f3-ec4b-00842a34199b"
      },
      "outputs": [],
      "source": [
        "print('Dataset: ', len(train_imgs))\n",
        "print('Descriptions: train=', len(train_descriptions))\n",
        "print('Photos: train=', len(train_features))\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Description Length: ', max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5BG_r9z9kof",
        "outputId": "13cf341a-b0fa-4c7d-d4f1-8b4853fc689a"
      },
      "outputs": [],
      "source": [
        "generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
        "print(generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiDeI-Bh78tA",
        "outputId": "97dd0f36-169b-4c02-b0b1-0f19ab224c28"
      },
      "outputs": [],
      "source": [
        "for i in range(epochs):\n",
        "  generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
        "  custom_model.fit(generator, epochs=1, steps_per_epoch= steps, verbose=1)\n",
        "  custom_model.save(\"models/model_\" + str(i) + \".h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4z6XvIo9b_0"
      },
      "outputs": [],
      "source": [
        "image_path  = '/content/10815824_2997e03d76.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "givCX0evPK22"
      },
      "outputs": [],
      "source": [
        "def image_features(filename, model):\n",
        "  try:\n",
        "    image = Image.open(filename)\n",
        "  except:\n",
        "    print(\"ERROR: Couldn't open image! Make sure the image path and extension is correct\")\n",
        "  image = image.resize((299,299))\n",
        "  image = np.array(image)\n",
        "  # for images that has 4 channels, we convert them into 3 channels\n",
        "  if image.shape[2] == 4:\n",
        "    image = image[..., :3]\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  image = image/127.5\n",
        "  image = image - 1.0\n",
        "  feature = model.predict(image)\n",
        "  return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvsLP3TCP2Pr"
      },
      "outputs": [],
      "source": [
        "def word_for_id(integer, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == integer:\n",
        "      return word\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phJZaagSQwDk"
      },
      "outputs": [],
      "source": [
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "  in_text = 'start'\n",
        "  for i in range(max_length):\n",
        "    sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "    sequence = pad_sequences([sequence], maxlen=max_length,padding='post') #[0]\n",
        "    pred = model.predict([photo,sequence], verbose=0)\n",
        "    pred = np.argmax(pred)\n",
        "    word = word_for_id(pred, tokenizer)\n",
        "    if word is None:\n",
        "      break\n",
        "    if word == 'end':\n",
        "      break\n",
        "    in_text += ' ' + word\n",
        "    if word == 'end':\n",
        "      break\n",
        "  return in_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGcHicb2bjmk"
      },
      "outputs": [],
      "source": [
        "max_length = 14\n",
        "tokenizer = load(open(\"/content/tokenizer.p\",\"rb\"))\n",
        "xception_model = Xception(include_top=False, pooling=\"avg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjiRyKnNqT97"
      },
      "outputs": [],
      "source": [
        "vselected_model = custom_model(vocab_size,max_length,2048)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP8k9QJMqz0d"
      },
      "outputs": [],
      "source": [
        "vselected_model.load_weights(\"/content/model_9.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMRkZ10e9s8m"
      },
      "outputs": [],
      "source": [
        "img_path = \"/content/667626_18933d713e.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "MlUhQeHo9zaN",
        "outputId": "d736a746-4164-4678-beea-4eba0e870419"
      },
      "outputs": [],
      "source": [
        "photo = image_features(img_path, xception_model)\n",
        "img = Image.open(img_path)\n",
        "generated_description = generate_desc(vselected_model, tokenizer, photo, max_length)\n",
        "print(\"\\n\\n\")\n",
        "print(generated_description)\n",
        "plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22f9ee3f6bb04bfbbfb1249086030254": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39063d4432cb47c7b53b7c09466b5788": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49ec0820913943ce9aee528ebcbe953b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ee8eab0dad84bd5b9eb6da2e8c977ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ef525f5acf44e329e968cb5ca089299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "570f1682692546399c986f39c00ff723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81cb9921fd11434b9d48d508ab5ecd56",
              "IPY_MODEL_78f76da1996242e8b055987c910f4a1a",
              "IPY_MODEL_74027dc0135e4348b8082509d6edcddd"
            ],
            "layout": "IPY_MODEL_22f9ee3f6bb04bfbbfb1249086030254"
          }
        },
        "65fa32362f9c44ea977a5264c0334609": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74027dc0135e4348b8082509d6edcddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39063d4432cb47c7b53b7c09466b5788",
            "placeholder": "​",
            "style": "IPY_MODEL_65fa32362f9c44ea977a5264c0334609",
            "value": " 0/? [01:54&lt;?, ?it/s]"
          }
        },
        "78f76da1996242e8b055987c910f4a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ef525f5acf44e329e968cb5ca089299",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c11e6bbbceca434b85144dd845822e94",
            "value": 0
          }
        },
        "81cb9921fd11434b9d48d508ab5ecd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ee8eab0dad84bd5b9eb6da2e8c977ad",
            "placeholder": "​",
            "style": "IPY_MODEL_49ec0820913943ce9aee528ebcbe953b",
            "value": ""
          }
        },
        "c11e6bbbceca434b85144dd845822e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
